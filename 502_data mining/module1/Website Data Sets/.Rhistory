install.packages("ROCR")
}
library(ROCR)
p<-predict(model,newdata=subset(test,select=c(2,3,4,5,6,7,8)),type="response")
pr<-prediction(p,test$Survived)
prf<-performance(pr,measure="tpr",x.measure="fpr")
plot(prf)
auc<-performance(pr,measure="auc")
print(auc@y.values[[1]]>auc)
install.packages("cluster")
knitr::opts_chunk$set(echo = TRUE)
library(cluster)
pga <- read.csv('lpga2008.csv')
library(cluster)
pga <- read.csv('lpga2008.csv')
knitr::opts_chunk$set(echo = TRUE)
#load dataset
library(cluster)
pga <- read.csv('lpga2008.csv')
#build clusters with the agnes function
pga_clusters <- agnes(pga,method="complete")
plot(pga_clusters)
knitr::opts_chunk$set(echo = TRUE)
#load dataset
library(cluster)
pga <- read.csv('lpga2008.csv')
#build clusters with the agnes function (agglomerative)
pga_clusters <- agnes(pga,method="complete")
plot(pga_clusters)
#divisive clustering with the diana function
#load dataset
library(cluster)
pga <- read.csv('lpga2008.csv')
#build clusters with the agnes function (agglomerative)
pga_clusters <- agnes(pga,method="complete")
plot(pga_clusters,main="Dendrogram of Agnes: Aglomerative clustering of pga")
#divisive clustering with the diana function
pga_div_clusters <- diana(pga)
pltree(pga_div, cex = 0.6, hang = -1, main = "Dendrogram of diana: Divisive clustering of pga")
#load dataset
library(cluster)
pga <- read.csv('lpga2008.csv')
#build clusters with the agnes function (agglomerative)
pga_clusters <- agnes(pga,method="complete")
plot(pga_clusters,main="Dendrogram of Agnes: Aglomerative clustering of pga")
#divisive clustering with the diana function
pga_div_clusters <- diana(pga)
pltree(pga_div_clusters, cex = 0.6, hang = -1, main = "Dendrogram of diana: Divisive clustering of pga")
knitr::opts_chunk$set(echo = TRUE)
#pull csv data and overview
shoppers.data <- read.csv("online_shoppers_intention.csv")
head(shoppers.data)
#pull csv data and overview
shoppers.data <- read.csv("online_shoppers_intention.csv")
print(as.data.frame(head(shoppers.data)))
knitr::opts_chunk$set(echo = TRUE)
#Chapter 3: Question 21
#read our nutritional data in
df = read.csv("C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets/nutrition_subset.csv")
#Chapter 3: Question 21
#read our nutritional data in
df = read.csv("C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets/nutrition_subset.csv")
names(df)
#sort by saturated fat
df.sorted = df[order(saturated_fat)]
)
df.sorted = df[order(df$saturated_fat)]
#sort by saturated fat
df.sorted = df[order(saturated_fat)]
#sort by saturated fat
df.sorted = df[order(saturated_fat),]
df.sorted = df[order(df$saturated_fat),]
df.sorted
#sort by saturated fat
df.sorted_desc = df[order(-df$saturated_fat),]
head(df)
head(df.sorted_desc)
#Chapter 3: Question 21
#read our nutritional data in
df = read.csv("C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets/nutrition_subset.csv")
#a:sort by saturated fat
df.sorted_desc = df[order(-df$saturated_fat),]
#get top five food items
df.top_five = head(df,n=5)
#print our top five
print(df.top_five)
#a:sort by saturated fat
df.sorted_desc = df[order(-df$saturated_fat),]
#get top five food items
df.top_five = tail(df,n=5)
#print our top five
print(df.top_five)
#a:sort by saturated fat
df.sorted_desc = df[order(-df$saturated_fat),]
#get top five food items
df.top_five = head(df,n=5)
#print our top five
print(df.top_five)
#a:sort by saturated fat
df.sorted_desc = df[order(df$saturated_fat,decreasing=TRUE),]
#get top five food items
df.top_five = head(df,n=5)
#print our top five
print(df.top_five)
#a:sort by saturated fat
df.sorted_desc = df[order(saturated_fat,decreasing=TRUE),]
#Chapter 3: Question 21
#read our nutritional data in
df = read.csv("C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets/nutrition_subset.csv")
#a:sort by saturated fat
df.sorted_desc = df[order(df$saturated_fat,decreasing=TRUE),]
#get top five food items
df.top_five = head(df,n=5)
#print our top five
print(df.top_five)
#a:sort by saturated fat
df.sorted_desc = df[order(df$saturated_fat,decreasing=TRUE),]
#get top five food items
df.top_five = head(df.sorted_desc,n=5)
#print our top five
print(df.top_five)
#create our new variable
df$satured_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$satured_fat_per_gram,decreasing=TRUE)]
#create our new variable
df$saturated_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$satured_fat_per_gram,decreasing=TRUE)]
#create our new variable
df$saturated_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$saturated_fat_per_gram,decreasing=TRUE)]
#create our new variable
df$saturated_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$saturated_fat_per_gram,decreasing=TRUE),]
#b. get the food with the most saturated fat per gram
print(head(df.sorted_by_sfpg,n=1))
#create our new variable
df$saturated_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$saturated_fat_per_gram,decreasing=TRUE),]
#b. get the food with the most saturated fat per gram
most_sfpg = subset(head(df.sorted_by_sfpg,n=1),select=c(food.item,saturated_fat_per_gram))
print(most_sfpg)
#create new variable
df$cholesterol_per_gram = df$cholesterol/df$weight_in_grams
#sort dataset, produce top five, output food with the most cholesterol
df.sorted_chol = df[order(df$cholesterol_per_gram,decreasing=TRUE),]
df.top_five_chol = head(df.sorted_chol,n=5)
print(df.top_five_chol)
#create new variable
df$cholesterol_per_gram = df$cholesterol/df$weight_in_grams
#sort dataset, produce top five, output food with the most cholesterol
df.sorted_chol = df[order(df$cholesterol_per_gram,decreasing=TRUE),]
df.top_five_chol = subset(head(df.sorted_chol,n=5),select=c(food.item,cholesterol_per_gram))
print(df.top_five_chol)
df$sfpg.std = (df$saturated_fat_per_gram - mean(df$saturated_fat_per_gram)) / sd(df$saturated_fat_per_gram)
df
hist(df$sfpg.std)
mean(df$sfpg.std)
std(df$sfpg.std)
sd(df$sfpg.std)
hist(df$satured_fat_per_gram)
hist(df$satured_fat)
hist(df$satured_fat_per_gram)
df$saturated_fat = df$satured_fat_per_gram
knitr::opts_chunk$set(echo = TRUE)
#Chapter 3
#read our nutritional data in
df = read.csv("C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets/nutrition_subset.csv")
#QUESTION 21
#a:sort by saturated fat
df.sorted_desc = df[order(df$saturated_fat,decreasing=TRUE),]
#get top five food items
df.top_five = head(df.sorted_desc,n=5)
#print our top five
print(df.top_five)
#create our new variable
df$saturated_fat_per_gram = df$saturated_fat/df$weight_in_grams
#a. sort by saturated fat per gram
df.sorted_by_sfpg = df[order(df$saturated_fat_per_gram,decreasing=TRUE),]
#b. get the food with the most saturated fat per gram
most_sfpg = subset(head(df.sorted_by_sfpg,n=1),select=c(food.item,saturated_fat_per_gram))
print(most_sfpg)
#create new variable
df$cholesterol_per_gram = df$cholesterol/df$weight_in_grams
#sort dataset, produce top five, output food with the most cholesterol
df.sorted_chol = df[order(df$cholesterol_per_gram,decreasing=TRUE),]
df.top_five_chol = subset(head(df.sorted_chol,n=5),select=c(food.item,cholesterol_per_gram))
print(df.top_five_chol)
#standardize data using z score
df$sfpg.std = (df$saturated_fat_per_gram - mean(df$saturated_fat_per_gram)) / sd(df$saturated_fat_per_gram)
hist(df$saturated_fat_per_gram)
hist(df$sfpg.std)
hist(df$saturated_fat_per_gram)
hist(df$saturated_fat_per_gram)
df$saturated_fat_per_gram
hist(df$sfpg.std)
hist(df$saturated_fat_per_gram)
plot(pdf(df$saturated_fat_per_gram))
plot(density(df$saturated_fat_per_gram))
print(plot(density(df$saturated_fat_per_gram)))
(plot(density(df$saturated_fat_per_gram)))
#begin
d <- density(df$saturated_fat_per_gram) # returns the density data
plot(d)
#begin
d <- density(df$saturated_fat_per_gram) # returns the density data
plot(d)
#standardize data using z score
df$sfpg.std = (df$saturated_fat_per_gram - mean(df$saturated_fat_per_gram)) / sd(df$saturated_fat_per_gram)
#we define outliers as greater than three standard deviations and produce
df.outliers_high = subset(df,df$sfpg.std >= 3)
df.outliers_low = subset(df,df$sfpg.std <= -3)
#print outlier
#begin by looking at distribution
d <- density(df$saturated_fat_per_gram) # returns the density data
plot(d)
chisq.out.test()
install.packages("outliers")
require(outliers)
chisq.out.test(df$saturated_fat_per_gram)
require(outliers)
chisq.out.test(df$saturated_fat_per_gram)
#standardize
df$sfpg.std = scale(x = df$saturated_fat_per_gram)
df$sfpg.std
plot(df$saturated_fat_per_gram)
hist(df$sfpg.std)
plot(density(df$sfpg.std))
abs(-1)
require(outliers)
chisq.out.test(df$saturated_fat_per_gram)
#standardize
df$sfpg.std = scale(x = df$saturated_fat_per_gram)
subset(abs(df$sfpg.std) >= 3)
require(outliers)
chisq.out.test(df$saturated_fat_per_gram)
#standardize
df$sfpg.std = scale(x = df$saturated_fat_per_gram)
subset(df,abs(df$sfpg.std) >= 3)
df$cpg_z <- scale(df$cholesterol_per_gram)
subset(df,abs(df$cpg_z) >= 3)
plot(density(df$cholesterol_per_gram))
df$cpg_z <- scale(df$cholesterol_per_gram)
subset(df,(df$cpg_z) >= 3)
file_dir = "C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets"
setwd(file_dir)
#get test and train datasets
train = read.csv("adult_ch6_training")
test  = read.csv("adult_ch6_test")
#we're going to use marital status and cap losses to predict income.
#first, we get the distribution of income.
barplot(table(train$Income)/nrow(train))
#change to factors:
test$Marital.status = factor(test$Marital.status)
test$Income         = factor(test$Income)
#install.packages(c("rpart", "rpart.plot"))
library(rpart)
library(rpart.plot)
cart01 <- rpart(formula = Income ~ Marital.status + Cap_Gains_Losses,data = test, method = "class")
rpart.plot(cart01)
log2(10)
0.4 * log2(0.4) + (0.6 * log2(0.6))
-(0.4 * log2(0.4)) - (0.6 * log2(0.6))
-((4/9) * log2(4/9)) - ((6/9) * log2(6/9))
-((4/9) * log2(4/9)) - ((5/9) * log2(5/9))
entropy <- function(t1,t2,f1,f2){
t = t1+t2
f = f1+f2
e_t = ((t1/t) * log2(t1/t)) + ((t2/t)* log2(t2/t))
e_f = ((f1/f) * log2(f1/f)) + ((f2/f)*log2(f2/f))
}
entropy(0,0,4,5)
entropy <- function(t1,t2,f1,f2){
t = t1+t2
f = f1+f2
n = t+f
e_t = ((t1/t) * log2(t1/t)) + ((t2/t)* log2(t2/t))
e_f = ((f1/f) * log2(f1/f)) + ((f2/f)*log2(f2/f))
e = ((t/n) * e_t) + ((f/n) * e_f)
return (e)
}
entropy(0,0,4,5)
entropy <- function(t1,t2,f1,f2){
t = t1+t2
f = f1+f2
n = t+f
if(t > 0){
e_t = ((t1/t) * log2(t1/t)) + ((t2/t)* log2(t2/t))
t_n = t/n
}else{
e_t=0
t_n = 0
}
if(f>0){
e_f = ((f1/f) * log2(f1/f)) + ((f2/f)*log2(f2/f))
f_n = f/n
}else{
f_n = 0
e_f=0
}
e = ((t/n) * e_t) + ((f/n) * e_f)
return (e)
}
entropy(0,0,0,0)
entropy(1,1,1,1)
entropy(1,0,3,5)
entropy <- function(a,b){
if (a==0 & b==0){return(0)}
if (a * b == 0){return(1)}
a1 = a/(a+b)
b1 = b/(a+b)
e = ((a1*log2(a1)) + (b1*log2(b1))) * -1
return (e)
}
entropy(0,0)
entropy(1,0)
entropy(1,1)
entropy(3,5)
entropy(4,5)
entropy(3,5)
E_MAIN = entropy(4,5)
E_MAIN - ((8/9)*entropy(3,5) + (1/9)*entropy(1,0))
entropy <- function(a,b){
if (a==0 & b==0){return(0)}
if (a * b == 0){return(0)}
a1 = a/(a+b)
b1 = b/(a+b)
e = ((a1*log2(a1)) + (b1*log2(b1))) * -1
return (e)
}
E_MAIN - ((8/9)*entropy(3,5) + (1/9)*entropy(1,0))
entropy(3,5)*(8/9)
entropy(1,1)
x = (2/9) * entropy(1,1) + (7/9) * entropy(3,4)
y = (3/9) * entropy(2,1) + (6/9) * entropy(2,4)
z = (5/9) * entropy(2,3) + (4/9) * entropy(2,2)
w = (6/9) * entropy(3,3) + (3/9) * entropy(1,2)
v = (8/9) * entropy(4,4) + (1/9) * entropy(0,1)
x
E_MAIN - x
y
E_MAIN-z
y = ((3/9) * entropy(2,1)) + (6/9) * entropy(2,4)
y
E_MAIN
E_MAIN-y
z
w
v
1/6
**2
(1/6)**2
(1/6)**2 + (5/6)**2
(1/6)**2 + (5/6)**2 - 1
.75**2
.75**2 + .25**2
-1
.75**2 + .25**2 - 1
(.75**2 + .25**2 - 1 ) * (4/9)
(.2**2 + .8**2 - 1 ) * (5/9)
-0.16666667
(.2**2 + .8**2 - 1 ) * (5/9) - 0.16666667
1 - .4**2 - .6**2
(1 - .4**2 - .6**2) * (5/9)
1 - .5**2 - .5**2
.5 * (4/9)
knitr::opts_chunk$set(echo = TRUE)
file_dir = "C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets"
setwd(file_dir)
df = read.csv("bank_marketing_training")
head(df)
#a bar graph of marital
barplot(df$marital)
#a bar graph of marital
barplot(table(df$marital))
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
file_dir = "C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets"
setwd(file_dir)
df = read.csv("bank_marketing_training")
#a bar graph of marital
barplot(table(df$marital))
#b bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_
#b bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_bar(aes(fill = response_variable)) + coord_flip()
head(df)
#b bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_bar(aes(fill = response)) + coord_flip()
#normalized bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_bar(aes(fill = response),position = "fill") + coord_flip()
#a bar graph of marital
barplot(table(df$marital),col = red)
#a bar graph of marital
barplot(table(df$marital),col = "red")
#the addmargins function creates a row and column to table A=t.v1 called "total" which contains the sum of the rows and columns
t.v1 <- table(df$response, df$marital)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
#
round(prop.table(t.v1, margin = 2)*100, 1)
print(t1)
t.v1
#the addmargins function creates a row and column to table A=t.v1 called "total" which contains the sum of the rows and columns
t.v1 <- table(df$response, df$marital)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
#print with percentages and without
print(t.v1)
print(round(prop.table(t.v1, margin = 2)*100, 1))
t.v1 <- table(df$marital, df$response)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
print(round(prop.table(t.v1, margin = 2)*100, 1))
t.v1 <- table(df$response,df$marital)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
print(round(prop.table(t.v1, margin = 1)*100, 1))
#histogram of duration
hist(df$duration)
#histogram of duration with overlay of response
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black")
#histogram of duration with overlay of response
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 500)
#histogram of duration
hist(df$duration,breaks = 30)
#histogram of duration with overlay of response
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 30)
#histogram of duration with overlay of response
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 250)
#histogram of duration
hist(df$duration,breaks = 250)
#histogram of duration
hist(df$duration,breaks = 10)
#histogram of duration
hist(df$duration,breaks = 20)
#histogram of duration
ggplot(df, aes(duration)) +
geom_histogram( color="black",binwidth = 250)
#normalized histogram of duration with overlay of response.
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 250,position="fill")
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
file_dir = "C:/Users/Filipp/Documents/usd_data_sci/502_data mining/module1/Website Data Sets"
setwd(file_dir)
df = read.csv("bank_marketing_training")
#a bar graph of marital
barplot(table(df$marital),col = "red")
#b bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_bar(aes(fill = response)) + coord_flip()
#normalized bar graph of marital with overlay of response
ggplot(df, aes(marital)) + geom_bar(aes(fill = response),position = "fill") + coord_flip()
#the addmargins function creates a row and column to table A=t.v1 called "total" which contains the sum of the rows and columns
t.v1 <- table(df$response, df$marital)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
#print with percentages and without
print(t.v1)
print(round(prop.table(t.v1, margin = 2)*100, 1))
t.v1 <- table(df$response,df$marital)
t.v2 <- addmargins(A = t.v1, FUN = list(total = sum),quiet = TRUE)
print(round(prop.table(t.v1, margin = 1)*100, 1))
#histogram of duration
ggplot(df, aes(duration)) +
geom_histogram( color="black",binwidth = 250)
#histogram of duration with overlay of response
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 250)
#normalized histogram of duration with overlay of response.
ggplot(df, aes(duration)) +
geom_histogram(aes(fill = response), color="black",binwidth = 250,position="fill")
#load in data sets
adult.training = read.csv("adult_ch6_training")
dir()
#load in data sets
adult.training = read.csv("adult_ch6_training")
x = read.csv("adult_ch6_training")
x
#load in data sets
adult.training = read.csv("adult_ch6_training")
#load in data sets
train = read.csv("adult_ch6_training")
#load in data sets
x = read.csv("adult_ch6_training")
#load in data sets
x = read.csv("adult_ch6_training")
head(x)
x = read.csv("adult_ch6_training")
#load in data sets
x = read.csv("adult_ch6_training")
test = read.csv("adult_ch6_test")
test
library(rpart)
library(rpart.plot)
#using marital status and capital gains and losses
#factorize
train$Marital.status = factor(train$Marital.status)
train$Cap_Gains_Losses = factor(train$Cap_Gains_Losses)
cart01 <- rpart(formula = Income ~ Marital.status + Cap_Gains_Losses,data = test, method = "class")
rpart.plot(cart01)
#using marital status and capital gains and losses
#factorize
train$Marital.status = factor(train$Marital.status)
train$Cap_Gains_Losses = factor(train$Cap_Gains_Losses)
cart01 <- rpart(formula = Income ~ Marital.status + Cap_Gains_Losses,data = train, method = "class")
rpart.plot(cart01)
#load in data sets
train = read.csv("adult_ch6_training")
